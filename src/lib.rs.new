//! A hierarchical time-series delta compression system for efficient historical state management.
//! 
//! This crate provides a way to store and query state changes over time with varying levels
//! of granularity, from milliseconds to centuries, using a fractal-like hierarchy of deltas.

#![warn(missing_docs)]
#![allow(clippy::new_without_default)]

use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::{
    collections::BTreeMap,
    path::Path,
    sync::Arc,
    thread,
    time::Duration,
};

#[cfg(windows)]
use winapi::um::{
    handleapi::CloseHandle,
    fileapi::{CreateFileW, OPEN_EXISTING},
    winnt::{FILE_ATTRIBUTE_NORMAL, FILE_READ_ATTRIBUTES, FILE_SHARE_READ, FILE_SHARE_WRITE, FILE_SHARE_DELETE},
};

use thiserror::Error as ThisError;

/// A simple wrapper for serializing Arc<T>
#[derive(Debug, Clone)]
struct ArcWrapper<T>(Arc<T>);

impl<T: Serialize> Serialize for ArcWrapper<T> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        self.0.serialize(serializer)
    }
}

impl<'de, T: Deserialize<'de>> Deserialize<'de> for ArcWrapper<T> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        T::deserialize(deserializer).map(|x| ArcWrapper(Arc::new(x)))
    }
}

/// Represents a change to the system state at a specific time
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Delta {
    /// The exact time this delta was created
    pub timestamp: DateTime<Utc>,
    /// The actual change data (serialized)
    pub data: Vec<u8>,
    /// Cryptographic hash of this delta
    pub hash: [u8; 32],
    /// Hash of the previous delta (forming a chain)
    pub prev_hash: Option<[u8; 32]>,
}

/// A collection of deltas within a specific time window
#[derive(Debug, Clone)]
pub struct TimeChunk {
    /// Start of this time window (inclusive)
    pub start_time: DateTime<Utc>,
    /// End of this time window (exclusive)
    pub end_time: DateTime<Utc>,
    /// All deltas within this window
    pub deltas: Vec<Delta>,
    /// Rolled-up summary of this chunk
    pub summary: Vec<u8>,
    /// Hash of this chunk (including all thralls)
    pub hash: [u8; 32],
    /// References to child chunks (thralls)
    pub thralls: Vec<TimeChunk>,
}

/// Serializable version of TimeChunk for serialization
#[derive(Serialize, Deserialize)]
struct SerializableTimeChunk {
    start_time: DateTime<Utc>,
    end_time: DateTime<Utc>,
    deltas: Vec<Delta>,
    summary: Vec<u8>,
    hash: [u8; 32],
    thralls: Vec<SerializableTimeChunk>,
}

impl TimeChunk {
    fn to_serializable(&self) -> SerializableTimeChunk {
        SerializableTimeChunk {
            start_time: self.start_time,
            end_time: self.end_time,
            deltas: self.deltas.clone(),
            summary: self.summary.clone(),
            hash: self.hash,
            thralls: self.thralls.iter().map(|t| t.to_serializable()).collect(),
        }
    }

    fn from_serializable(serializable: SerializableTimeChunk) -> Self {
        TimeChunk {
            start_time: serializable.start_time,
            end_time: serializable.end_time,
            deltas: serializable.deltas,
            summary: serializable.summary,
            hash: serializable.hash,
            thralls: serializable.thralls.into_iter().map(Self::from_serializable).collect(),
        }
    }
}

/// Manages the hierarchy of time chunks
/// Errors that can occur during time hierarchy operations
#[derive(Debug, ThisError)]
pub enum TimeHierarchyError {
    #[error("Verification failed: {0}")]
    VerificationError(String),
    
    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
    
    #[error("Serialization error: {0}")]
    SerializationError(#[from] serde_json::Error),
    
    #[error("Invalid time range: {0}")]
    InvalidTimeRange(String),
}

/// Statistics about a time hierarchy
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeHierarchyStats {
    /// Total number of chunks in the hierarchy
    pub chunk_count: usize,
    /// Total number of deltas across all chunks
    pub delta_count: usize,
    /// Total size of all deltas in bytes
    pub total_size_bytes: usize,
}

#[derive(Debug)]
pub struct TimeHierarchy {
    config: HierarchyConfig,
    chunks: BTreeMap<DateTime<Utc>, Arc<TimeChunk>>,
}

/// Configuration for the time hierarchy
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HierarchyConfig {
    /// List of time levels in the hierarchy
    pub levels: Vec<TimeLevel>,
    /// Base directory for storage
    pub base_dir: Option<String>,
}

/// Defines a level in the time hierarchy
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeLevel {
    /// Name of this level
    pub name: String,
    /// Duration in seconds
    pub duration_seconds: i64,
    /// Maximum number of chunks to keep at this level
    pub max_chunks: usize,
}

impl TimeLevel {
    /// Creates a new time level
    pub fn new(name: &str, duration_seconds: i64, max_chunks: usize) -> Self {
        TimeLevel {
            name: name.to_string(),
            duration_seconds,
            max_chunks,
        }
    }
    
    /// Gets the duration as a chrono::Duration
    pub fn duration(&self) -> chrono::Duration {
        chrono::Duration::seconds(self.duration_seconds)
    }
}

impl Default for TimeHierarchy {
    fn default() -> Self {
        let config = HierarchyConfig {
            levels: vec![
                TimeLevel::new("minute", 60, 60),
                TimeLevel::new("hour", 3600, 24),
                TimeLevel::new("day", 86400, 31),
                TimeLevel::new("month", 2592000, 12),
                TimeLevel::new("year", 31536000, 10),
                TimeLevel::new("decade", 315360000, 10),
                TimeLevel::new("century", 3153600000, 10),
            ],
            base_dir: None,
        };
        
        TimeHierarchy {
            config,
            chunks: BTreeMap::new(),
        }
    }
}

impl TimeHierarchy {
    /// Creates a new TimeHierarchy with default configuration
    pub fn new() -> Self {
        Self::default()
    }
    
    /// Creates a TimeHierarchy with a custom configuration
    pub fn with_config(config: HierarchyConfig) -> Self {
        TimeHierarchy {
            config,
            chunks: BTreeMap::new(),
        }
    }
    
    /// Adds a delta to the hierarchy
    pub fn add_delta(&mut self, delta: Delta) -> Result<(), TimeHierarchyError> {
        let chunk = self.get_or_create_chunk(delta.timestamp, 0)?;
        // Update chunk - implementation would add the delta and update hashes
        Ok(())
    }
    
    /// Truncates a timestamp to the start of a level
    pub fn truncate_to_level(&self, time: DateTime<Utc>, level: usize) -> DateTime<Utc> {
        if level >= self.config.levels.len() {
            return time; // Return unchanged if level is out of bounds
        }
        
        let duration = self.config.levels[level].duration();
        let timestamp = time.timestamp();
        let level_seconds = self.config.levels[level].duration_seconds;
        let truncated_timestamp = (timestamp / level_seconds) * level_seconds;
        
        Utc.timestamp_opt(truncated_timestamp, 0).unwrap()
    }
    
    /// Gets or creates a chunk for a specific time and level
    pub fn get_or_create_chunk(&mut self, timestamp: DateTime<Utc>, level: usize) -> Result<Arc<TimeChunk>, TimeHierarchyError> {
        let truncated_time = self.truncate_to_level(timestamp, level);
        
        // Return existing chunk if it exists
        if let Some(chunk) = self.chunks.get(&truncated_time) {
            return Ok(chunk.clone());
        }
        
        // Calculate end time
        let end_time = if level < self.config.levels.len() {
            truncated_time + self.config.levels[level].duration()
        } else {
            // Fallback for invalid level
            truncated_time + chrono::Duration::days(1)
        };
        
        // Create new chunk
        let chunk = TimeChunk {
            start_time: truncated_time,
            end_time,
            deltas: Vec::new(),
            summary: Vec::new(),
            hash: [0; 32], // Will be updated when adding deltas
            thralls: Vec::new(),
        };
        
        // When creating a chunk at a non-root level, we also need to create or update its parent
        if level < self.config.levels.len() - 1 {
            let _parent_chunk = self.get_or_create_chunk(timestamp, level + 1)?;
            // In a real implementation, we would add this chunk as a thrall to the parent
        }
        
        // Store chunk
        let arc_chunk = Arc::new(chunk);
        self.chunks.insert(truncated_time, arc_chunk.clone());
        
        Ok(arc_chunk)
    }
    
    /// Verifies the integrity of the time hierarchy
    pub fn verify_integrity(&self) -> Result<(), TimeHierarchyError> {
        let mut prev_hash = None;
        
        for (time, chunk) in &self.chunks {
            // Verify chunk's hash
            // Compute hash of chunk contents
            let mut hasher = sha2::Sha256::new();
            let serialized = serde_json::to_vec(&chunk.to_serializable())?;
            hasher.update(&serialized);
            let computed_hash = hasher.finalize().into();
            
            if computed_hash != chunk.hash {
                return Err(TimeHierarchyError::VerificationError(
                    format!("Hash mismatch at time {}", time)
                ));
            }
            
            // Verify hash chain
            if let Some(prev_hash_value) = prev_hash {
                if !chunk.deltas.is_empty() && chunk.deltas[0].prev_hash != Some(prev_hash_value) {
                    return Err(TimeHierarchyError::VerificationError(
                        "Hash chain broken".to_string()
                    ));
                }
            }
            
            // Update prev_hash for next iteration
            if !chunk.deltas.is_empty() {
                prev_hash = Some(chunk.deltas.last().unwrap().hash);
            }
        }
        
        Ok(())
    }
    
    /// Calculates statistics for the time hierarchy
    pub fn calculate_stats(&self) -> TimeHierarchyStats {
        let mut stats = TimeHierarchyStats {
            chunk_count: self.chunks.len(),
            delta_count: 0,
            total_size_bytes: 0,
        };
        
        for chunk in self.chunks.values() {
            stats.delta_count += chunk.deltas.len();
            for delta in &chunk.deltas {
                stats.total_size_bytes += delta.data.len();
            }
        }
        
        stats
    }
    
    /// Saves the time hierarchy to the specified directory
    pub fn save(&self, path: &Path) -> Result<(), TimeHierarchyError> {
        // Create directory if it doesn't exist
        self.create_dir_all_with_retry(path, 3)?;
        
        // Save each chunk to a separate file
        for (time, chunk) in &self.chunks {
            let filename = format!("chunk_{}.json", time.timestamp());
            let file_path = path.join(filename);
            
            let serialized = serde_json::to_string_pretty(&chunk.to_serializable())?;
            self.write_file_with_retry(&file_path, serialized.as_bytes(), 3)?;
        }
        
        // Save marker file with retry logic
        let marker = path.join(".civicjournal-time");
        self.write_file_with_retry(&marker, b"CivicJournal Time Hierarchy", 3)?;
        
        Ok(())
    }
    
    #[cfg(windows)]
    fn is_file_locked(&self, path: &Path) -> bool {
        use std::os::windows::ffi::OsStrExt;
        use std::ffi::OsStr;
        
        let path: Vec<u16> = OsStr::new(path)
            .encode_wide()
            .chain(Some(0).into_iter())
            .collect();
            
        unsafe {
            let handle = CreateFileW(
                path.as_ptr(),
                FILE_READ_ATTRIBUTES,
                FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
                std::ptr::null_mut(),
                OPEN_EXISTING,
                FILE_ATTRIBUTE_NORMAL,
                std::ptr::null_mut()
            );
            
            if handle.is_null() {
                true
            } else {
                CloseHandle(handle);
                false
            }
        }
    }
    
    #[cfg(not(windows))]
    fn is_file_locked(&self, _path: &Path) -> bool {
        false
    }
    
    fn create_dir_all_with_retry(&self, path: &Path, retries: u32) -> Result<(), TimeHierarchyError> {
        for attempt in 0..=retries {
            match std::fs::create_dir_all(path) {
                Ok(_) => return Ok(()),
                Err(e) if attempt == retries => return Err(e.into()),
                Err(_) => {
                    if self.is_file_locked(path) {
                        // If file is locked, wait and retry
                        thread::sleep(Duration::from_millis(100 * u64::from(attempt + 1)));
                    } else {
                        // Propagate other errors
                        return Err(std::io::Error::last_os_error().into());
                    }
                }
            }
        }
        unreachable!()
    }
    
    fn write_file_with_retry(&self, path: &Path, contents: &[u8], retries: u32) -> Result<(), TimeHierarchyError> {
        for attempt in 0..=retries {
            match std::fs::write(path, contents) {
                Ok(_) => return Ok(()),
                Err(e) if attempt == retries => return Err(e.into()),
                Err(_) => {
                    if self.is_file_locked(path) {
                        // If file is locked, wait and retry
                        thread::sleep(Duration::from_millis(100 * u64::from(attempt + 1)));
                    } else {
                        // Propagate other errors
                        return Err(std::io::Error::last_os_error().into());
                    }
                }
            }
        }
        unreachable!()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;
    
    #[test]
    fn test_truncate_to_level() {
        let hierarchy = TimeHierarchy::new();
        let time = Utc.with_ymd_and_hms(2023, 6, 15, 14, 30, 45).unwrap();
        
        // Test minute-level truncation
        let minute = hierarchy.truncate_to_level(time, 0);
        assert_eq!(minute, Utc.with_ymd_and_hms(2023, 6, 15, 14, 30, 0).unwrap());
        
        // Test hour-level truncation
        let hour = hierarchy.truncate_to_level(time, 1);
        assert_eq!(hour, Utc.with_ymd_and_hms(2023, 6, 15, 14, 0, 0).unwrap());
        
        // Test day-level truncation
        let day = hierarchy.truncate_to_level(time, 2);
        assert_eq!(day, Utc.with_ymd_and_hms(2023, 6, 15, 0, 0, 0).unwrap());
    }
    
    #[test]
    fn test_chunk_creation() {
        let mut hierarchy = TimeHierarchy::new();
        let time = Utc.with_ymd_and_hms(2023, 6, 15, 14, 30, 45).unwrap();
        
        // Create a chunk
        let chunk = hierarchy.get_or_create_chunk(time, 0).unwrap();
        assert_eq!(chunk.start_time, Utc.with_ymd_and_hms(2023, 6, 15, 14, 30, 0).unwrap());
        assert_eq!(chunk.end_time, Utc.with_ymd_and_hms(2023, 6, 15, 14, 31, 0).unwrap());
        
        // Should return the same chunk for the same time and level
        let same_chunk = hierarchy.get_or_create_chunk(time, 0).unwrap();
        assert_eq!(Arc::as_ptr(&chunk), Arc::as_ptr(&same_chunk));
    }
}
